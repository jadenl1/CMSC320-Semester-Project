# importing necessary libraries
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np


# Load the dataset into a DataFrame
df = pd.read_csv('NY-House-Dataset.csv')

# Display the first few rows of the DataFrame to verify the import
df.head()

# Preliminary cleaning
df_cleaned = df[['BROKERTITLE', 'TYPE', 'PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT', 'FORMATTED_ADDRESS', 'LATITUDE', 'LONGITUDE']].copy()
df_cleaned['BATH'] = df_cleaned['BATH'].apply(lambda x: round(x * 2) / 2)

# Extract City, State, and ZIP Code
def extract_location_info(address):
    parts = address.split(',')
    if len(parts) > 2:
        city = parts[-3].strip()
        state_zip = parts[-2].strip().split(' ')
        state = state_zip[0]
        zip_code = state_zip[1] if len(state_zip) > 1 else None
        return city, state, zip_code
    return None, None, None

df_cleaned[['CITY', 'STATE', 'ZIP']] = df_cleaned.apply(lambda row: pd.Series(extract_location_info(row['FORMATTED_ADDRESS'])), axis=1)

# Ensure Data Type Consistency
df_cleaned['PRICE'] = pd.to_numeric(df_cleaned['PRICE'], errors='coerce')
df_cleaned['PROPERTYSQFT'] = pd.to_numeric(df_cleaned['PROPERTYSQFT'], errors='coerce')

# Check for and Remove Duplicate Entries
df_cleaned.drop_duplicates(subset=['FORMATTED_ADDRESS', 'PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT'], inplace=True)

# Checking for missing values in key columns and handling them
df_cleaned.dropna(subset=['PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT'], inplace=True)

# After cleaning
display(df_cleaned.head(100))

# Filter the dataset to include only the main property types
main_property_types = ['Co-op for sale', 'House for sale', 'Condo for sale', 'Multi-family home for sale', 'Townhouse for sale']
df_filtered = df_cleaned[df_cleaned['TYPE'].isin(main_property_types)]

# Perform ANOVA to compare the prices across different property types
anova_result = stats.f_oneway(
    df_filtered[df_filtered['TYPE'] == 'Co-op for sale']['PRICE'],
    df_filtered[df_filtered['TYPE'] == 'House for sale']['PRICE'],
    df_filtered[df_filtered['TYPE'] == 'Condo for sale']['PRICE'],
    df_filtered[df_filtered['TYPE'] == 'Multi-family home for sale']['PRICE'],
    df_filtered[df_filtered['TYPE'] == 'Townhouse for sale']['PRICE']
)

print(f"ANOVA test statistic: {anova_result.statistic}")
print(f"p-value: {anova_result.pvalue}")

# Setting the aesthetic style of the plots
sns.set_style("whitegrid")

# Create a boxplot to visualize the distribution of prices for each property type
plt.figure(figsize=(12, 8))
sns.boxplot(x='TYPE', y='PRICE', data=df_filtered, order=main_property_types)
plt.title('Price Distribution by Property Type')
plt.xlabel('Property Type')
plt.ylabel('Price')
plt.xticks(rotation=45)
plt.yscale('log')  # Using a logarithmic scale for better visualization of wide price ranges
plt.tight_layout()

# Show the plot
plt.show()

from scipy.stats import chi2_contingency

# Creating a contingency table for "CITY" and "TYPE"
contingency_table = pd.crosstab(df_cleaned['CITY'], df_cleaned['TYPE'])

# Performing the Chi-square test of independence
_, p_value, _, _ = chi2_contingency(contingency_table)

print(p_value)

import matplotlib.pyplot as plt
import seaborn as sns

# Limiting the data to the top 10 cities by frequency to keep the chart readable
top_cities = df_cleaned['CITY'].value_counts().head(10).index

# Further limiting the data to the top house types for visualization
top_types = df_cleaned['TYPE'].value_counts().head(5).index

# Filtering the DataFrame to include only rows that match the top cities and types
filtered_df = df_cleaned[df_cleaned['CITY'].isin(top_cities) & df_cleaned['TYPE'].isin(top_types)]

# Creating the plot
plt.figure(figsize=(14, 8))
sns.countplot(data=filtered_df, x='CITY', hue='TYPE', order=top_cities, hue_order=top_types)
plt.title('Distribution of House Types Across Top 10 Cities')
plt.xticks(rotation=45)
plt.xlabel('City')
plt.ylabel('Count')
plt.legend(title='House Type', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()

from scipy.stats import norm

# Assuming population_mean and population_std are known
population_mean = 500000  # Hypothetical national average price
population_std = 150000   # Known standard deviation of national prices

# Filter the dataset for a specific category (e.g., condos)
sample_data = df_cleaned[df_cleaned['TYPE'] == 'Condo for sale']
sample_mean = sample_data['PRICE'].mean()
sample_size = len(sample_data)

# Calculate the Z-score
z_score = (sample_mean - population_mean) / (population_std / (sample_size**0.5))

# Calculate the p-value for a two-tailed test
p_value = 2 * norm.sf(abs(z_score))

print(f"Sample Mean: {sample_mean}, Sample Size: {sample_size}, Z-Score: {z_score}, P-Value: {p_value}")


# Assume population_mean, population_std, and sample_mean are defined
population_dist = np.random.normal(population_mean, population_std, 10000)

# Plotting
plt.figure(figsize=(10, 6))
sns.histplot(population_dist, kde=True, stat='density', label='Population Distribution')
plt.axvline(x=population_mean, color='green', linestyle='--', label='Population Mean ($500,000)')
plt.axvline(x=sample_mean, color='red', linestyle='-', label=f'Sample Mean (${sample_mean:,.2f})')

# Marking critical regions for alpha = 0.05 in a two-tailed test
plt.axvline(x=population_mean + 1.96 * population_std / np.sqrt(sample_size), color='black', linestyle='--', label='Critical Value (+1.96)')
plt.axvline(x=population_mean - 1.96 * population_std / np.sqrt(sample_size), color='black', linestyle='--', label='Critical Value (-1.96)')

plt.title('Population Distribution with Sample Mean')
plt.xlabel('Price')
plt.ylabel('Density')
plt.legend()
plt.show()
